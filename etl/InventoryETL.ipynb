{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace049a7-ecea-4795-a20f-222b1edc1016",
   "metadata": {},
   "source": [
    "# Shop incentory analysis and ETL\n",
    "\n",
    "The purpose of this notebook is to convert data provided by the client to the expected format, so they are loadable into SQL db. The structure of this file divides it into classic 3 sections:\n",
    "\n",
    "1. Extract -> loading the data, clearing any issues\n",
    "2. Transform -> reshape the data\n",
    "3. Load -> check the quality and save the results\n",
    "\n",
    "## 1. Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84ffb7-76fe-4fbe-bc6f-99798944b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cca782-9e7e-4c4f-bb89-12bcb2464a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls inputs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4c049-8571-4f5e-8403-dc815521635e",
   "metadata": {},
   "source": [
    "There are 3 files delivered: inventory, prices and meta. First, a look into inventory.\n",
    "\n",
    "## 1.1. Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a2eb44-238b-44f3-837e-a66f72dc16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head inputs/coding_challenge_inventory.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17089551-4384-4811-a845-8968ee148578",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory = pd.read_csv(\"inputs/coding_challenge_inventory.csv\", index_col=False)\n",
    "inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee267fe6-14e3-4f80-aa9f-7a3205fd5ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4138b-e625-43dc-8bb7-76c5021e11a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccfcc67-676f-4599-b4cd-87c898542956",
   "metadata": {},
   "source": [
    "It looks like a properly formatted CSV file, first two columns are described as integers. What can worry a bit here is the negative inventory level for some items, let's have a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbce5a3-f9df-4c32-9392-251df5231653",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory[inventory[\"inventory_level\"] < 0][[\"item_number\", \"inventory_level\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a35405e-8741-4336-a61a-3336944f2858",
   "metadata": {},
   "source": [
    "Entries with `-1` and `-2` look like a counting issue (I guess it can happen in real life scenarios in shops), but `-2259` and `-12738` look quite suspicious (considering the max for positive numbers is `1400`). Either there was some issue on generating these, of something is really odd with these products. We're going to import these, but it's worthy to ask the client for explanation.\n",
    "\n",
    "Also, the final format requires report timestamp as one field, let's check if all seems fine here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ed1b3-7c0a-4e18-b639-164054ce8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory[\"report_timestamp\"] = pd.to_datetime(\n",
    "    inventory[\"report_date\"] + \" \" + inventory[\"report_time\"]\n",
    ")\n",
    "inventory[inventory[\"report_timestamp\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264a85e3-f7ae-41f2-9b47-461e5152bae3",
   "metadata": {},
   "source": [
    "All entries are properly converted, no need to worry and we can move on to the next file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf0727-ad14-4343-b8fa-53829f2daaa4",
   "metadata": {},
   "source": [
    "## 1.2. Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e7727-ba5e-4ba1-b856-b93a83233c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head inputs/coding_challenge_meta.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c76ff-6d23-43aa-9518-4aa152988dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pd.read_csv(\"inputs/coding_challenge_meta.csv\", index_col=False)\n",
    "except pd.errors.ParserError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29023c9-d43d-4e1f-b1f8-899bd85774bc",
   "metadata": {},
   "source": [
    "Parser fails in the very beginning, so it looks the `.csv` extension here doesn't really mean it's a valid CSV file... Let's have a look on reported line 33:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db22443e-8fbe-4b5a-ae3e-5547d86b9f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat inputs/coding_challenge_meta.csv | sed -n '1p; 33p'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c15773-55f6-47d6-b9e4-9762e540e2d9",
   "metadata": {},
   "source": [
    "First fields look propely formatted:\n",
    "\n",
    "* product_upc: 000000000001030054325\n",
    "* item_number: 10061658\n",
    "* item_description: Eloquent Modest Mestorf\n",
    "* case_upc: null\n",
    "* case_pack: 12.0\n",
    "* department: 1\n",
    "\n",
    "But the last field, `supplier`, looks like not propetly quoted string with comma inside (as name of the company \"Sth, Inc\" is quite common form). We're going to fix it by parsing supplier having in mind this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f7971-f44d-43c4-939a-a31ad162207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_fixer(arr):\n",
    "    number_in_case_pack_column = arr[4].replace(\".\", \"\").isnumeric()\n",
    "    number_in_department_column = arr[5].isnumeric()\n",
    "    if number_in_case_pack_column and number_in_department_column:\n",
    "        arr[6] = \",\".join(arr[6:])\n",
    "    else:\n",
    "        raise ValueError(\"Unhandled issue\")\n",
    "    arr = arr[:7]\n",
    "    return arr\n",
    "\n",
    "\n",
    "meta = pd.read_csv(\n",
    "    \"inputs/coding_challenge_meta.csv\", on_bad_lines=line_fixer, engine=\"python\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a7cd3-8829-464d-bda8-2b70c306bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f659f-c382-4b23-b244-00ada55385f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03dc7f-e07d-4102-8b5c-fe3d3ed790c6",
   "metadata": {},
   "source": [
    "Numeric columns look good - `product_upc` and `item_number` is always there, `case_upc` is optional (only on 167 rows) and case_pack is missing on a 6 records.\n",
    "\n",
    "But, there is something wrong with `department` column - looking the the file in text format indicates that this is an integer (with all values `1` in the first 9 records), but pandas sees this as `object` (so probably a string). Let's see the set of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda451b-9afc-47bd-b0ab-1517ffbbbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"department\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073ed1be-72c3-4a07-9bcf-45e6da66236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_department_values = [\n",
    "    dept\n",
    "    for dept in meta[\"department\"].unique()\n",
    "    if isinstance(dept, str) and not dept.isnumeric()\n",
    "]\n",
    "rows_with_wrong_department = meta[\n",
    "    meta[\"department\"].isin(non_numeric_department_values)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac77d8-5733-4bb6-9ae6-d913ad0a3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    meta.loc[[23, 24]]\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea2c89-e8f1-4d1c-9dd2-b917d5d3f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    meta.loc[[82, 83]]\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0131e-441f-46c8-8e32-fe18c5115baf",
   "metadata": {},
   "source": [
    "It looks like a nother issue in the CSV file with department being ommited from the consecutive rows for the same `item_number`... Let's double check if this is always the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a0da0-6c4b-4536-ae48-e25791f65872",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows_with_wrong_department.iterrows():\n",
    "    previous_row_supplier = meta.loc[row[0] - 1, \"supplier\"]\n",
    "    invalid_row_department = row[1].department\n",
    "    previous_row_item_number = meta.loc[row[0] - 1, \"item_number\"]\n",
    "    invalid_row_item_number = row[1].item_number\n",
    "    assert previous_row_supplier == invalid_row_department\n",
    "    assert previous_row_item_number == invalid_row_item_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f21d8b-48f4-44ca-b6b7-023d1204b9dd",
   "metadata": {},
   "source": [
    "Yes, it's always the case. Thankfully, we need supplier id only on `item_number` level (not `product_upc` level), so we can basically clear the invalid department values. Or - even easier - since the deparment doesn't need to be imported into final SQL db, we can drop the entire column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d95368-0770-494f-9394-add17673d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.drop(\"department\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2dda99-c839-4d0f-8bbc-e678cbca25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25afa58d-9a9a-436c-9d89-f11d5f6cdbe5",
   "metadata": {},
   "source": [
    "## 1.3. Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66ce8d-90c5-43d8-9caf-0df0e6e48f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv(\"inputs/coding_challenge_prices.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623ec757-34d1-43eb-b86a-a6aedd0920c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ec671-464b-4779-8aeb-8c068ce0e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd19c66-34a2-43fc-8e63-fc7ff883cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83d682-8935-4bbb-b1e3-f26bd4d386c5",
   "metadata": {},
   "source": [
    "Third csv looks really good - nothing suspicious there, just a 2-column standard CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad130e54-5e61-4754-847b-51d8a64ac938",
   "metadata": {},
   "source": [
    "# 2. Transform\n",
    "\n",
    "First, let's find the products in `meta` that are not real products but variants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d4fcd-75c8-4ff0-9fe1-2871ceb13e8c",
   "metadata": {},
   "source": [
    "# 2.1. Handling duplicates UPCs\n",
    "\n",
    "The final data require UPC column with unique constraint. According to the documentation:\n",
    "\n",
    "> HINT: If a `upc` has multiple `item_number` values in the product metadata file, then that\n",
    "means the product has multiple variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaa467d-7a28-4971-b1a0-7d83a87c3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"duplicated_upcs\"] = meta.groupby(\"product_upc\").item_number.transform(\"nunique\")\n",
    "duplicated_upcs = meta[meta[\"product_upc\"].duplicated()][\"product_upc\"].to_list()\n",
    "meta[meta[\"duplicated_upcs\"] > 1].sort_values(\"product_upc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd392892-9642-45fd-bd5f-e856436dff5c",
   "metadata": {},
   "source": [
    "So, we have 2 cases with variants. Unfortunately, their descriptions and item numbers do not match, this indicates probable issue with `upc` data entry. What is more, it looks prices also contain duplicates for these `upc` codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d5c6a2-052a-4ddf-976c-129f502f6b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices[prices[\"product_upc\"].isin(duplicated_upcs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278c610-025d-48d1-97b0-4a5fe8f3dc96",
   "metadata": {},
   "source": [
    "In the normal curcuimstances, these issues with unique identifiers should be consulted with team responsible for the data delivery, but in our case, for simplicity and to make sure we can make `upc` a unique column, I will assume the first row for every product is the proper indicator of `item_number` and `item_description`, and the second row is a variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5a043-40e5-4e4e-afd9-38df135104f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta[~meta[\"product_upc\"].duplicated()].copy()\n",
    "prices = prices[~prices[\"product_upc\"].duplicated()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff2d5d-46bb-4252-9e2e-d502c3e77ce9",
   "metadata": {},
   "source": [
    "Eventually, `product_upc` should be unique across `meta` and `prices`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65482999-2d8f-4720-9fcc-96ac4e70d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta[\"product_upc\"].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407bb7a0-0e33-40af-b4d0-6c979c5ce053",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices[prices[\"product_upc\"].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc9439-d284-4e32-9a53-592d55dc893d",
   "metadata": {},
   "source": [
    "Let's check the current row indices for these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6badbb-b628-4377-a9c6-bf8d67ca3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta[\"product_upc\"].isin(duplicated_upcs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e8aeeb-266b-4463-a5b0-071e1d50bc7b",
   "metadata": {},
   "source": [
    "And, we can build variants alternates now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a32444-9180-4c1b-af15-0dc0e1c1c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_duplicated_upcs = (\n",
    "    meta[meta[\"product_upc\"].isin(duplicated_upcs)]\n",
    "    .reset_index()[[\"index\", \"product_upc\"]]\n",
    "    .rename(columns={\"index\": \"product_id\", \"product_upc\": \"upc\"})\n",
    ")\n",
    "variants_duplicated_upcs[\"alternate_type\"] = \"variant\"\n",
    "variants_duplicated_upcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b32e5-95d5-4099-8a66-ce0e2fd71b40",
   "metadata": {},
   "source": [
    "## 2.2. Handling variants of products\n",
    "\n",
    "Then, we need to handle variants, so rows when one item has multiple UPCs. First, lets ensure that all the items have the same description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee3af1-5896-4f4c-b128-cff3fb51ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"unique_upcs\"] = meta.groupby(\"item_number\").product_upc.transform(\"nunique\")\n",
    "meta[\"unique_names\"] = meta.groupby(\"item_number\").item_description.transform(\"nunique\")\n",
    "meta[(meta[\"unique_upcs\"] > 1) & (meta[\"unique_names\"] != 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2abd50-67a7-4c04-a7d1-35ee674a0d1c",
   "metadata": {},
   "source": [
    "Thankfully, all the item names are consistent across variants. So we just create a set of variants by using first row as primary product, and a second one as a duplicate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ebd19-0cf1-4e67-81b9-982dcf57b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_having_variants = meta[meta[\"item_number\"].duplicated()][\"item_number\"].to_list()\n",
    "all_products_with_wariants = meta[meta[\"item_number\"].isin(items_having_variants)]\n",
    "main_products = all_products_with_wariants[\n",
    "    ~all_products_with_wariants[\"item_number\"].duplicated()\n",
    "]\n",
    "main_products_mapping = main_products.reset_index()[[\"item_number\", \"index\"]].rename(\n",
    "    columns={\"index\": \"product_id\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f75276-3102-411b-ab6b-4dbfaa4617ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = (\n",
    "    meta[meta[\"item_number\"].duplicated()]\n",
    "    .merge(main_products_mapping, on=\"item_number\")[[\"product_id\", \"product_upc\"]]\n",
    "    .rename(columns={\"product_upc\": \"upc\"})\n",
    ")\n",
    "variants[\"alternate_type\"] = \"variant\"\n",
    "variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431dce74-cc2e-45f3-a3bf-423f617e94b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta[~meta[\"item_number\"].duplicated()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43563b08-8b10-4419-be5d-3f3ee1bd6743",
   "metadata": {},
   "source": [
    "## 2.3. Handling case alternates\n",
    "\n",
    "Finally, creating a set of case alternates seems quite simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea6813-bb90-41fc-9d18-1fc264def69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = (\n",
    "    meta[meta[\"case_upc\"].notnull()]\n",
    "    .reset_index()[[\"index\", \"case_upc\", \"case_pack\"]]\n",
    "    .rename(columns={\"index\": \"product_id\", \"case_upc\": \"upc\"})\n",
    ")\n",
    "cases[\"alternate_type\"] = \"case\"\n",
    "cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9681d0ba-b32a-4337-9a02-bef9e4cb0b88",
   "metadata": {},
   "source": [
    "## 2.4. Creating alternates\n",
    "\n",
    "Eventually, we combine all the sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e1bb9c-1136-4dbe-9f50-4e4b8aab15b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_alternates = pd.concat([variants_duplicated_upcs, variants, cases])\n",
    "product_alternates[\"upc\"] = (\n",
    "    product_alternates[\"upc\"].astype(\"int64\").astype(\"string\").str.zfill(14)\n",
    ")\n",
    "product_alternates = product_alternates.reset_index(drop=True)\n",
    "product_alternates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab227b2-a18a-4ba4-b657-0e0eff62e92b",
   "metadata": {},
   "source": [
    "## 2.5. Creating products\n",
    "\n",
    "In `products` table we need products with their price and inventory. Therefore, first, lets join `meta` and `prices`. We know already that there are no duplicates of join key between these, therefore, the result of left join should contain as many rows as `meta` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb34633-ce3f-4e2c-a019-b015c9944dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.reset_index()\n",
    "len(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025ced0-9767-4f78-8a8b-6eada6f8c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_with_prices = meta.merge(prices, on=\"product_upc\", how=\"left\")\n",
    "meta_with_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bb10ca-0cf0-4e20-b191-fcc82881f2ca",
   "metadata": {},
   "source": [
    "Before joining inventory, let's check for duplicates there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedf7a9a-44f5-4adc-b17d-1034dc49b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory[inventory[\"item_number\"].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec4fb14-12b6-4a6e-9f95-b18ab98b99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_with_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ce9b6-936e-4ba0-9735-87bdc5325478",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = meta_with_prices.merge(inventory, on=\"item_number\", how=\"left\")\n",
    "products = products.set_index(\"index\")\n",
    "products = products[\n",
    "    [\n",
    "        \"product_upc\",\n",
    "        \"item_description\",\n",
    "        \"item_number\",\n",
    "        \"price\",\n",
    "        \"supplier\",\n",
    "        \"inventory_level\",\n",
    "        \"report_timestamp\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"product_upc\": \"upc\",\n",
    "        \"item_description\": \"name\",\n",
    "        \"report_timestamp\": \"inventory_updated_at\",\n",
    "    }\n",
    ")\n",
    "products[\"upc\"] = products[\"upc\"].astype(\"int64\").astype(\"string\").str.zfill(14)\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de94d33-87d4-4d15-bf64-7318b8206e18",
   "metadata": {},
   "source": [
    "# 3. Load\n",
    "\n",
    "We have all the tables ready, but before saving them into DB, let's make sure they pass the simple data quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba00f44-ab74-4a6a-a14b-e38093246b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is upc unique?\n",
    "assert not products[\"upc\"].duplicated().any(), \"Duplicates on UPC\"\n",
    "\n",
    "# do we have all products?\n",
    "meta = pd.read_csv(\n",
    "    \"inputs/coding_challenge_meta.csv\", on_bad_lines=line_fixer, engine=\"python\"\n",
    ")\n",
    "assert len(products) == len(meta) - len(duplicated_upcs) - len(\n",
    "    variants\n",
    "), \"Products missing\"\n",
    "\n",
    "# can we consider product_id in alternates a foreign key?\n",
    "assert len(\n",
    "    products.reset_index().merge(\n",
    "        product_alternates, left_on=\"index\", right_on=\"product_id\"\n",
    "    )\n",
    ") == len(product_alternates), \"Foreign key issue\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb4363-60a4-4a1d-8356-3bc963df6200",
   "metadata": {},
   "source": [
    "All looks clean, it's time to save those as CSVs, so they can be loaded into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5608ff-fbdc-4ca0-99dd-5b9bd5f075f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "products.to_csv(\"outputs/products.csv\", index_label=\"product_id\")\n",
    "product_alternates.to_csv(\n",
    "    \"outputs/product_alternates.csv\", index_label=\"product_alternate_id\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
